{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self,input_size,output_size,batch_size,data_x,data_y,loss_function,grad,init,f):\n",
    "        '''batch_size: how many elements in one batch\n",
    "        loss_function: f(np.array,np.array)->double\n",
    "        grad: a list of grad function, each of which f(x,y,theta,output_size)->np.array\n",
    "        init: initial theta, which is a list of all parameters. (i.e. [C,b1,W,b2])\n",
    "        f: the fitting function. f(x)=pred_y\n",
    "        '''\n",
    "        self.outsize=output_size\n",
    "        self.insize=input_size\n",
    "        tensor_x=torch.FloatTensor(data_x)\n",
    "        batch_num=int(tensor_x.size()[0]/batch_size)\n",
    "        self.x=tensor_x.reshape(batch_num,batch_size,input_size)\n",
    "        tensor_y=torch.FloatTensor(data_y)\n",
    "        self.y=tensor_y.reshape(batch_num,batch_size,1)\n",
    "        self.loss=0.0\n",
    "        self.lossf=loss_function\n",
    "        self.theta=init\n",
    "        self.alpha=0.1\n",
    "        self.grad=grad\n",
    "        self.f=f\n",
    "        \n",
    "    def adjust_rate(self,alpha):\n",
    "        self.alpha=alpha\n",
    "        \n",
    "    def forward(self):\n",
    "        batch_num=self.x.size()[0]\n",
    "        batch_size=self.x.size()[1]\n",
    "        theta_num=len(self.theta)\n",
    "        \n",
    "        \n",
    "        #Update parameters\n",
    "        for i in range(batch_num):\n",
    "            grad_list=[[] for k in range(theta_num)]\n",
    "\n",
    "            for j in range(batch_size):               \n",
    "                x=self.x[i,j,:].numpy()\n",
    "                y=self.y[i,j,:].numpy()[0]\n",
    "\n",
    "                for k in range(theta_num):\n",
    "                    outsize=self.outsize\n",
    "                    grad_theta=self.grad[k](x,y,self.theta,outsize)\n",
    "                    grad_list[k].append(grad_theta)\n",
    "\n",
    "            for k in range(theta_num):\n",
    "                grad_result=np.mean(grad_list[k],axis=0)\n",
    "                self.theta[k]-=self.alpha*grad_result\n",
    "            \n",
    "        #Shuffle\n",
    "        temp_x=self.x.reshape(batch_num*batch_size,self.insize)\n",
    "        temp_y=self.y.reshape(batch_num*batch_size,1)\n",
    "        new_index=torch.randperm(batch_num*batch_size)\n",
    "        new_x=temp_x[new_index,:]\n",
    "        new_y=temp_y[new_index,:]\n",
    "        self.x=new_x.reshape(batch_num,batch_size,self.insize)\n",
    "        self.y=new_y.reshape(batch_num,batch_size,1)\n",
    "        \n",
    "    def predict(self,data_x):\n",
    "        tensor_x=torch.FloatTensor(data_x)\n",
    "\n",
    "        sample_num=int(tensor_x.size()[0])\n",
    "\n",
    "        output_list=[]\n",
    "        for i in range(sample_num):\n",
    "            x=tensor_x[i,:].numpy()\n",
    "            y=self.f(x,self.theta)\n",
    "            output_list.append(y)\n",
    "        return output_list\n",
    "    \n",
    "    def get_error(self):\n",
    "        batch_num=self.x.size()[0]\n",
    "        batch_size=self.x.size()[1]\n",
    "        data_x=self.x.reshape(batch_num*batch_size,self.insize)\n",
    "        data_y=self.y.reshape((batch_num*batch_size,1))\n",
    "        y_list=self.predict(data_x)\n",
    "        \n",
    "        error_list=[]\n",
    "        for i in range(len(y_list)):\n",
    "            y=y_list[i]\n",
    "            y_real=data_y[i,:].numpy()[0]\n",
    "            error_list.append(self.lossf(y,y_real))\n",
    "            \n",
    "        self.loss=np.mean(error_list)\n",
    "        return np.mean(error_list)\n",
    "    \n",
    "    def save(self):\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load MNIST data\n",
    "MNIST_data = h5py.File('MNISTdata.hdf5', 'r')\n",
    "x_train = np.float32(MNIST_data['x_train'][:] )\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of inputs\n",
    "num_inputs = 28*28\n",
    "#number of outputs\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For logistics\n",
    "\n",
    "def vec_transpose(x):\n",
    "    y=np.array([x])\n",
    "    return y.T\n",
    "\n",
    "def normalize(x):\n",
    "    y=torch.FloatTensor(x)\n",
    "    mean=torch.mean(y)\n",
    "    std=torch.std(y)\n",
    "    y=(y-mean)/std\n",
    "    return y\n",
    "\n",
    "def cross_entropy_error(x,y):\n",
    "    return -np.log(x[int(y)])\n",
    "\n",
    "def softmax(z):\n",
    "    ez=np.exp(z)\n",
    "    return ez/np.sum(ez)\n",
    "\n",
    "def grad_C(x,y,theta,output_size):\n",
    "    ey=np.zeros(output_size)\n",
    "    ey[int(y)]=1\n",
    "    #print(np.dot(theta,x))\n",
    "    out=-np.dot(vec_transpose(ey-softmax(np.dot(theta[0],x))),np.array([x]))\n",
    "    return out\n",
    "\n",
    "def f_1(x,theta):\n",
    "    return softmax(np.dot(theta[0],x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
